Metadata-Version: 2.4
Name: Denabase
Version: 0.2.0
Summary: A production-quality library for building and querying a verified SAT encoding library.
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: numpy
Requires-Dist: networkx
Requires-Dist: pydantic>=2.0
Requires-Dist: python-sat[aiger,pblib]
Requires-Dist: scikit-learn
Requires-Dist: joblib
Requires-Dist: datasets
Requires-Dist: tqdm
Requires-Dist: faiss-cpu
Requires-Dist: pyvis
Provides-Extra: test
Requires-Dist: pytest; extra == "test"
Requires-Dist: hypothesis; extra == "test"

# LLM-SAT: Agentic Constraint Solving

Hi! Here is the updated README : D
I changed a good amount of things since our last meeting on friday, including some new instances. If you want to simply interact with how the system works, here is a command to run a relatively easy instance:

python3 bench/run_bench.py --id mrpp_8x8_4r_T20_sat_central_block --provider google --insecure

Also, if you are on macOS, keeping the --insecure flag is helpful as it bypasses potential SSL certificate issues with the Python urllib calls to the Gemini API. 
If there is any info missing in the README please let me know. Cheers, Guillaume




LLM-SAT is a **ReAct-based Agentic Framework** that bridges the gap between high-level natural language reasoning and low-level SAT/Constraint solving. It uses Large Language Models (LLMs) to formulate problems and rigorous solvers (PySAT, MiniZinc) to solve them.

---

## üöÄ How it Works: The 5-Phase Lifecycle

The agent operates in a strictly phased environment, enforced by the **SATManager** "referee". This ensures the model is built incrementally and correctly.

### 1. üîç OBSERVATION (Discovery)
The agent analyzes the problem description to extract grid sizes, piece counts, blocked cells, and movement rules.
- **Action**: `UPDATE_PLAN`
- **Goal**: Populate `PLAN.md` with enough observations to advance.

### 2. üî¢ VARIABLES (State Space)
The agent defines a discrete search space by mapping observations to Boolean or Integer variables.
- **Actions**: `DEFINE_VARIABLES`, `DEFINE_VARIABLE_PATTERN`
- **Output**: A registered variable registry (e.g., `pos_robot1_t0_x0_y1`).

### 3. ‚öñÔ∏è CONSTRAINTS (Logic Formulation)
The agent translates mathematical or logical rules into high-level IR (Internal Representation) constraints.
- **Actions**: `ADD_MODEL_CONSTRAINTS`, `ADD_PYTHON_CONSTRAINT_BLOCK`
- **Kinds**: `exactly_one`, `at_most_k`, `implies`, `all_different`, etc.
- **Verification**: `FUZZ_CONSTRAINTS` or `TEST_CONSTRAINT` can be used to "locally" verify logic before a full solve.

### 4. ‚ö° IMPLEMENTATION (JIT Compilation & Solving)
The `SATManager` JIT-compiles the high-level model into low-level instructions (CNF, Pseudo-Boolean, or FlatZinc) and executes the backend solver.
- **Action**: `SOLVE`
- **Backends**: `pb` (Pseudo-Boolean), `cnf` (Raw SAT), `minizinc` (Constraint Programming).

### 5. üõ† REFINEMENT (Debugging)
If the solver returns `UNSAT` (unexpectedly) or fails validation, the agent analyzes the failure, critiques its model, and iterates.
- **Action**: `REFINE_FROM_VALIDATION`, `REMOVE_MODEL_CONSTRAINTS`

---

## üõ† Action Reference

| Action | Description |
| :--- | :--- |
| **`UPDATE_PLAN`** | Update `PLAN.md` with observations and goals. |
| **`ADVANCE_PHASE`** | Transition to the next stage of the lifecycle. |
| **`DEFINE_VARIABLES`** | Register individual Boolean variables. |
| **`DEFINE_VARIABLE_PATTERN`**| Register variable families (e.g., `grid_{row}_{col}`). |
| **`ADD_MODEL_CONSTRAINTS`** | Add high-level logic (ExactlyOne, AtMostK, etc.). |
| **`ADD_PYTHON_CONSTRAINT_BLOCK`** | **Power User**: Execute Python code to generate complex constraints programmatically. |
| **`FUZZ_CONSTRAINTS`** | Generate random test cases to verify the JIT compiler's output. |
| **`TEST_CONSTRAINT`** | Verify a specific constraint against a manual truth-table entry. |
| **`SOLVE`** | Compile and run the backend solver. |
| **`DECODE_SOLUTION`** | Map raw boolean assignments back to domain variables. |
| **`FINISH`** | Complete the task and provide the final solution. |

## üèÉ Running Benchmarks

Use the `run_bench.py` script to execute the agent on specific problems or entire families.

```bash
python3 bench/run_bench.py [ARGS]
```

### CLI Arguments

| Argument | Description |
| :--- | :--- |
| **`--id <id>`** | Run a specific instance by its ID (e.g., `poly_pentomino_10x6_hole_sat`). |
| **`--family <name>`**| Filter instances by family (e.g., `mrpp`, `pentomino`). |
| **`--provider <p>`** | LLM Provider: `google` (default), `openai`, `ollama`, or `mock`. |
| **`--model <m>`** | Specify the model name (e.g., `gemini-1.5-pro-latest`). |
| **`--IR <backend>`** | Choose the IR Backend: `pb` (default), `cnf`, or `minizinc`. |
| **`--max_steps <n>`** | Limit the number of steps the agent can take (default: 30). |
| **`--insecure`** | **macOS Tip**: Bypass SSL certificate verification for Python's `urllib`. |
| **`--api_key <key>`** | Provide the API key manually instead of using `.env`. |

---

## üèó Project Structure

- **`engine/`**: The core logic.
    - `agent.py`: The ReAct loop and tool-calling coordinator.
    - `sat_manager.py`: The "Referee" and JIT compiler entry point.
    - `backends/`: Transformation logic for `pb`, `cnf`, and `minizinc`.
    - `vars.py`: Global variable registry and ID mapper.
- **`bench/`**: Benchmark harness.
    - `run_bench.py`: CLI to run specific instances or families.
    - `instances/`: JSON-encoded problems (GraphColoring, Pentomino, MRPP).
    - `checkers/`: Domain-specific Python validators for solutions.
- **`memory/`**: Workspace for intermediate solver files (e.g., `.fzn`, `.opb`).

---

## üîß Installation & Setup

1. **Install Dependencies**:
   ```bash
   pip install -r requirements.txt
   ```
   *Note: Requires `python-sat` and optionally `minizinc` installed on your PATH.*

2. **Configure Environment**:
   ```bash
   cp .env.example .env
   # Add your GOOGLE_API_KEY (for Gemini) or use Ollama for local runs.
   ```

3. **Run a Benchmark**:
   ```bash
   # Run a specific problem instance
   python3 bench/run_bench.py --id poly_pentomino_10x6_hole_sat --provider google
   ```

---

## üõ° Verification & Fuzzing

The repo includes a built-in **Fuzzing Engine** to prevent "modeling errors" from wasting solver time. When the agent adds a complex Python block, it can call `FUZZ_CONSTRAINTS` to generate 50+ random assignments, checking if the solver's result (SAT/UNSAT) matches the expected logic for that specific constraint subset.

---

> [!IMPORTANT]
> **Deterministic Phasing**: The agent CANNOT skip to `SOLVE` without passing through `VARIABLES` and `CONSTRAINTS`. The `SATManager` will reject out-of-order actions.



# Denabase

Denabase is a robust Python library for building, indexing, and querying a verified SAT encoding library. It features CNF fingerprinting, similarity retrieval, and metamorphic verification.

## Installation

To install the library in editable mode:

```bash
pip install -e .
```

To install with testing dependencies (required for running tests):

```bash
pip install -e '.[test]'
```

## Quickstart

The Denabase CLI provides commands to initialize a database, ingest CNF/IR problems, and query for similar entries.

### 1. Initialize a Database
Initialize a new database directory structure.
```bash
python Denabase/denabase_cli.py init ./my_denabase
```

### 2. Add a CNF Entry
Ingest a raw DIMACS CNF file. Use `--verify` to enforce strict verification checks (metamorphic testing) before ingestion.
```bash
# Standard ingestion
python Denabase/denabase_cli.py add-cnf ./my_denabase problem.cnf --family "crypto" --problem-id "sha256-preimage"

# Verified ingestion (computationally expensive, guarantees correctness)
python Denabase/denabase_cli.py add-cnf ./my_denabase problem.cnf --family "crypto" --problem-id "sha256-preimage" --verify
```

### 3. Add an IR Entry
Ingest an Intermediate Representation (JSON) file.
```bash
# Standard ingestion
python Denabase/denabase_cli.py add-ir ./my_denabase problem_ir.json --family "scheduling" --problem-id "job-shop-01"

# Verified ingestion
python Denabase/denabase_cli.py add-ir ./my_denabase problem_ir.json --family "scheduling" --problem-id "job-shop-01" --verify
```

### 4. Query Similar Entries
Find similar entries based on structural fingerprints and profile embeddings.
```bash
# Query with a CNF file
python Denabase/denabase_cli.py query ./my_denabase query.cnf --topk 5

# Query with an IR file
python Denabase/denabase_cli.py query ./my_denabase query_ir.json --topk 5
```

## Running Tests

Ensure you have installed the test dependencies:
```bash
pip install -e '.[test]'
```

Run the test suite using `pytest`:
```bash
pytest
```
Or for less verbose output:
```bash
pytest -q
```
